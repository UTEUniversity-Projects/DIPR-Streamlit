import numpy as np
import streamlit as st
import cv2
import os
import unicodedata
import re
import time
import threading
from datetime import datetime

def name_to_folder_name(name):
    """Convert Vietnamese name to folder name format"""
    # Convert to ASCII and lowercase
    name = unicodedata.normalize('NFKD', name).encode('ascii', 'ignore').decode('ascii')
    name = name.lower()
    # Replace spaces with underscores
    name = re.sub(r'[^a-z0-9]+', '_', name).strip('_')
    return name

@st.cache_resource
def load_face_detector():
    from utils.face_utils import FaceDetector
    return FaceDetector("models/face_detection_yunet_2023mar.onnx")

@st.cache_resource
def load_face_recognizer():
    from utils.face_utils import FaceRecognizer
    return FaceRecognizer("models/face_recognition_sface_2021dec.onnx", "data/db_embeddings.pkl")

def show():
    # ThÃªm pháº§n giá»›i thiá»‡u
    with st.expander("ğŸ” Giá»›i thiá»‡u vá» Ä‘Äƒng kÃ½ khuÃ´n máº·t", expanded=False):
        st.markdown("""
        ### Giá»›i thiá»‡u vá» Ä‘Äƒng kÃ½ khuÃ´n máº·t
        
        TÃ­nh nÄƒng Ä‘Äƒng kÃ½ khuÃ´n máº·t má»›i lÃ  má»™t pháº§n quan trá»ng trong há»‡ thá»‘ng nháº­n dáº¡ng khuÃ´n máº·t, cho phÃ©p há»‡ thá»‘ng há»c vÃ  nháº­n dáº¡ng khuÃ´n máº·t cá»§a ngÆ°á»i dÃ¹ng má»›i.
        
        #### Quy trÃ¬nh Ä‘Äƒng kÃ½ khuÃ´n máº·t
        
        Quy trÃ¬nh Ä‘Äƒng kÃ½ khuÃ´n máº·t bao gá»“m cÃ¡c bÆ°á»›c chÃ­nh sau:
        
        1. **Thu tháº­p dá»¯ liá»‡u**: Chá»¥p nhiá»u áº£nh khuÃ´n máº·t tá»« cÃ¡c gÃ³c vÃ  Ä‘iá»u kiá»‡n Ã¡nh sÃ¡ng khÃ¡c nhau
        2. **PhÃ¡t hiá»‡n khuÃ´n máº·t**: Sá»­ dá»¥ng YuNet Ä‘á»ƒ phÃ¡t hiá»‡n vÃ  cáº¯t vÃ¹ng khuÃ´n máº·t tá»« áº£nh
        3. **CÄƒn chá»‰nh khuÃ´n máº·t**: CÄƒn chá»‰nh khuÃ´n máº·t Ä‘á»ƒ chuáº©n hÃ³a vá»‹ trÃ­ cá»§a cÃ¡c Ä‘áº·c Ä‘iá»ƒm
        4. **TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng**: Sá»­ dá»¥ng SFace Ä‘á»ƒ chuyá»ƒn Ä‘á»•i áº£nh khuÃ´n máº·t thÃ nh vector embedding 128 chiá»u
        5. **LÆ°u trá»¯ database**: LÆ°u trá»¯ vector Ä‘áº·c trÆ°ng cÃ¹ng vá»›i nhÃ£n (tÃªn ngÆ°á»i) vÃ o database
        
        #### CÃ´ng nghá»‡ sá»­ dá»¥ng
        
        - **YuNet** Ä‘á»ƒ phÃ¡t hiá»‡n khuÃ´n máº·t vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao, ngay cáº£ trong Ä‘iá»u kiá»‡n Ã¡nh sÃ¡ng khÃ¡c nhau
        - **SFace** Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng khuÃ´n máº·t thÃ nh vector 128 chiá»u, táº¡o "chá»¯ kÃ½ sinh tráº¯c há»c" duy nháº¥t
        - **PhÆ°Æ¡ng phÃ¡p chuáº©n hÃ³a** Ä‘á»ƒ Ä‘áº£m báº£o cÃ¡c vector cÃ³ cÃ¹ng Ä‘á»™ dÃ i vÃ  dá»… dÃ ng so sÃ¡nh
        - **LÆ°u trá»¯ hiá»‡u quáº£** sá»­ dá»¥ng Pickle Ä‘á»ƒ lÆ°u trá»¯ database vector Ä‘áº·c trÆ°ng
        
        #### Táº§m quan trá»ng cá»§a sá»‘ lÆ°á»£ng máº«u
        
        Há»‡ thá»‘ng thu tháº­p 100 máº«u khuÃ´n máº·t cho má»—i ngÆ°á»i Ä‘á»ƒ:
        - TÄƒng Ä‘á»™ chÃ­nh xÃ¡c trong nháº­n dáº¡ng
        - Äáº£m báº£o nháº­n dáº¡ng Ä‘Æ°á»£c trong nhiá»u Ä‘iá»u kiá»‡n khÃ¡c nhau
        - Giáº£m thiá»ƒu lá»—i nháº­n dáº¡ng sai
        
        á»¨ng dá»¥ng nÃ y cung cáº¥p hai phÆ°Æ¡ng phÃ¡p Ä‘Äƒng kÃ½ khuÃ´n máº·t: tá»± Ä‘á»™ng vÃ  thá»§ cÃ´ng, giÃºp ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ lá»±a chá»n phÆ°Æ¡ng phÃ¡p phÃ¹ há»£p nháº¥t vá»›i nhu cáº§u cá»§a há».
        """)
            
    # ThÃªm pháº§n hÆ°á»›ng dáº«n
    with st.expander("ğŸ“‹ HÆ°á»›ng dáº«n sá»­ dá»¥ng", expanded=False):
        st.markdown("""
        ### HÆ°á»›ng dáº«n sá»­ dá»¥ng
        
        #### 1. Cháº¿ Ä‘á»™ tá»± Ä‘á»™ng (KhuyÃªn dÃ¹ng)
        
        Cháº¿ Ä‘á»™ nÃ y tá»± Ä‘á»™ng chá»¥p vÃ  xá»­ lÃ½ áº£nh khuÃ´n máº·t:
        
        1. **Chuáº©n bá»‹**:
           - Äáº£m báº£o camera hoáº¡t Ä‘á»™ng tá»‘t vÃ  Ä‘Æ°á»£c káº¿t ná»‘i
           - Äáº·t camera á»Ÿ nÆ¡i cÃ³ Ä‘á»§ Ã¡nh sÃ¡ng
           - Giá»¯ khuÃ´n máº·t trong khung hÃ¬nh tá»« 0.5-1m
        
        2. **Nháº­p thÃ´ng tin**:
           - Nháº­p há» tÃªn Ä‘áº§y Ä‘á»§ (sáº½ Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ nháº­n dáº¡ng sau nÃ y)
           - Äiá»u chá»‰nh sá»‘ lÆ°á»£ng áº£nh máº«u náº¿u cáº§n (máº·c Ä‘á»‹nh: 100)
        
        3. **QuÃ¡ trÃ¬nh chá»¥p**:
           - Nháº¥n "ğŸš€ Báº¯t Ä‘áº§u" Ä‘á»ƒ báº¯t Ä‘áº§u quÃ¡ trÃ¬nh
           - Di chuyá»ƒn Ä‘áº§u nháº¹ nhÃ ng Ä‘á»ƒ cÃ³ nhiá»u gÃ³c khÃ¡c nhau
           - CÃ³ thá»ƒ nháº¥n "â¸ï¸ Táº¡m dá»«ng" náº¿u cáº§n nghá»‰ giá»¯a chá»«ng
           - Nháº¥n "â¹ï¸ Dá»«ng" Ä‘á»ƒ káº¿t thÃºc quÃ¡ trÃ¬nh sá»›m
        
        4. **Cáº­p nháº­t database**:
           - Khi Ä‘Ã£ Ä‘á»§ sá»‘ lÆ°á»£ng áº£nh, nháº¥n "Cáº­p nháº­t Database"
           - Äá»£i quÃ¡ trÃ¬nh xá»­ lÃ½ vÃ  táº¡o vector Ä‘áº·c trÆ°ng hoÃ n táº¥t
        
        #### 2. Cháº¿ Ä‘á»™ thá»§ cÃ´ng
        
        PhÃ¹ há»£p khi báº¡n muá»‘n kiá»ƒm soÃ¡t tá»«ng áº£nh Ä‘Æ°á»£c chá»¥p:
        
        1. **Thiáº¿t láº­p**:
           - Nháº­p há» tÃªn Ä‘áº§y Ä‘á»§
           - Äiá»u chá»‰nh sá»‘ lÆ°á»£ng áº£nh máº«u
           - Nháº¥n "ğŸš€ Báº¯t Ä‘áº§u" Ä‘á»ƒ báº¯t Ä‘áº§u
        
        2. **Chá»¥p áº£nh**:
           - Nháº¥n "Space" hoáº·c nÃºt chá»¥p Ä‘á»ƒ chá»¥p áº£nh
           - Kiá»ƒm tra khuÃ´n máº·t Ä‘Ã£ Ä‘Æ°á»£c phÃ¡t hiá»‡n Ä‘Ãºng chÆ°a (khung xanh)
           - Nháº¥n "ğŸ’¾ LÆ°u áº£nh" Ä‘á»ƒ lÆ°u máº«u
           - Nháº¥n "ğŸ”„ Clear Photo" Ä‘á»ƒ chá»¥p láº¡i
        
        #### Máº¹o Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘t nháº¥t
        
        - **Ãnh sÃ¡ng**: Äáº£m báº£o khuÃ´n máº·t Ä‘Æ°á»£c chiáº¿u sÃ¡ng Ä‘áº§y Ä‘á»§ vÃ  Ä‘á»u
        - **Biá»ƒu cáº£m**: Thay Ä‘á»•i biá»ƒu cáº£m nháº¹ (má»‰m cÆ°á»i, nghiÃªm tÃºc) Ä‘á»ƒ tÄƒng Ä‘á»™ Ä‘a dáº¡ng
        - **GÃ³c nhÃ¬n**: Di chuyá»ƒn Ä‘áº§u nháº¹ nhÃ ng sang trÃ¡i, pháº£i, lÃªn, xuá»‘ng
        - **Phá»¥ kiá»‡n**: Thá»­ Ä‘eo/bá» kÃ­nh, thay Ä‘á»•i kiá»ƒu tÃ³c náº¿u cÃ³ thá»ƒ
        - **TrÃ¡nh chuyá»ƒn Ä‘á»™ng nhanh**: Di chuyá»ƒn tá»« tá»« Ä‘á»ƒ trÃ¡nh áº£nh bá»‹ má»
        
        #### Quáº£n lÃ½ database
        
        - Sá»­ dá»¥ng chá»©c nÄƒng "XÃ¢y dá»±ng láº¡i Database hoÃ n toÃ n" náº¿u muá»‘n lÃ m má»›i há»‡ thá»‘ng
        - "Kiá»ƒm tra Database hiá»‡n táº¡i" Ä‘á»ƒ xem danh sÃ¡ch ngÆ°á»i Ä‘Ã£ Ä‘Äƒng kÃ½ vÃ  sá»‘ lÆ°á»£ng máº«u
        - Restart á»©ng dá»¥ng sau khi cáº­p nháº­t database Ä‘á»ƒ Ã¡p dá»¥ng thay Ä‘á»•i
        """)
            
    # Choose capture mode
    tab1, tab2 = st.tabs(["ğŸ¥ Cháº¿ Ä‘á»™ tá»± Ä‘á»™ng", "ğŸ‘† Cháº¿ Ä‘á»™ thá»§ cÃ´ng"])
    
    with tab1:
        show_interactive_capture_ui()
    
    with tab2:
        show_manual_capture_ui()
    
    # Additional database management
    st.markdown("---")
    st.markdown("### Quáº£n lÃ½ Database")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("XÃ¢y dá»±ng láº¡i Database hoÃ n toÃ n", key="main_rebuild_db_button"):
            with st.spinner("Äang xÃ¢y dá»±ng database..."):
                detector = load_face_detector()
                recognizer = load_face_recognizer()
                output_dir = "data/faces"
                from utils.face_utils import build_face_database
                total_count = build_face_database(detector, recognizer, output_dir, "data/db_embeddings.pkl")
                st.success(f"âœ… Database Ä‘Ã£ Ä‘Æ°á»£c xÃ¢y dá»±ng vá»›i {total_count} khuÃ´n máº·t!")
                st.info("Vui lÃ²ng restart á»©ng dá»¥ng Ä‘á»ƒ Ã¡p dá»¥ng thay Ä‘á»•i.")
    
    with col2:
        if st.button("Kiá»ƒm tra Database hiá»‡n táº¡i", key="main_check_db_button"):
            db_path = "data/db_embeddings.pkl"
            if os.path.exists(db_path):
                try:
                    import pickle
                    with open(db_path, 'rb') as f:
                        database = pickle.load(f)
                    
                    st.success("Database tá»“n táº¡i vÃ  há»£p lá»‡")
                    st.write(f"Sá»‘ ngÆ°á»i: {len(database)}")
                    for name, features in database.items():
                        st.write(f"- {name}: {len(features)} áº£nh")
                except Exception as e:
                    st.error(f"Lá»—i khi Ä‘á»c database: {e}")
            else:
                st.warning("Database khÃ´ng tá»“n táº¡i. Vui lÃ²ng xÃ¢y dá»±ng database má»›i.")

def show_interactive_capture_ui():
    """Create an interactive capture UI without frequent reloads"""
    
    st.markdown("### ğŸ¥ Cháº¿ Ä‘á»™ chá»¥p tá»± Ä‘á»™ng (Interactive)")
    
    # Initialize session state
    if 'capture_running' not in st.session_state:
        st.session_state.capture_running = False
    if 'current_image_count' not in st.session_state:
        st.session_state.current_image_count = 0
    if 'person_name' not in st.session_state:
        st.session_state.person_name = ""
    if 'capturing_status' not in st.session_state:
        st.session_state.capturing_status = "Ready"  # Ready, Capturing, Paused
    if 'force_update' not in st.session_state:
        st.session_state.force_update = False
    if 'num_samples' not in st.session_state:
        st.session_state.num_samples = 100
    if 'folder_name' not in st.session_state:
        st.session_state.folder_name = ""
    
    # Input form
    col1, col2 = st.columns([3, 1])
    with col1:
        person_name = st.text_input("Há» vÃ  tÃªn", value=st.session_state.person_name, key="auto_person_name")
    with col2:
        num_samples = st.number_input("Sá»‘ áº£nh máº«u", min_value=50, max_value=200, value=100, key="auto_num_samples")
    
    # Control buttons
    col1, col2, col3 = st.columns(3)
    
    with col1:
        start_button = st.button("ğŸš€ Báº¯t Ä‘áº§u", disabled=st.session_state.capture_running, key="auto_start_button")
    with col2:
        pause_resume = st.button(
            "â¸ï¸ Táº¡m dá»«ng" if st.session_state.capturing_status != "Paused" else "â–¶ï¸ Tiáº¿p tá»¥c",
            disabled=not st.session_state.capture_running,
            key="auto_pause_resume_button"
        )
    with col3:
        stop_button = st.button("â¹ï¸ Dá»«ng", disabled=not st.session_state.capture_running, key="auto_stop_button")
    
    # Start capture
    if start_button and person_name:
        st.session_state.capture_running = True
        st.session_state.current_image_count = 0
        st.session_state.person_name = person_name
        st.session_state.num_samples = num_samples
        st.session_state.folder_name = name_to_folder_name(person_name)
        st.session_state.capturing_status = "Capturing"
        st.session_state.force_update = True
        st.rerun()
    elif start_button and not person_name:
        st.error("Vui lÃ²ng nháº­p há» tÃªn!")
    
    # Pause/Resume capture
    if pause_resume:
        if st.session_state.capturing_status == "Capturing":
            st.session_state.capturing_status = "Paused"
        else:
            st.session_state.capturing_status = "Capturing"
        # Don't rerun for pause/resume to avoid camera reload
    
    # Stop capture
    if stop_button:
        st.session_state.capture_running = False
        st.session_state.capturing_status = "Ready"
        st.session_state.force_update = True
        st.rerun()
    
    # Progress display (create placeholders)
    progress_placeholder = st.empty()
    status_placeholder = st.empty()
    count_placeholder = st.empty()
    video_placeholder = st.empty()
    
    # Update progress displays
    if st.session_state.capture_running:
        progress_placeholder.progress(st.session_state.current_image_count / st.session_state.num_samples)
        status_placeholder.write(f"**Tráº¡ng thÃ¡i:** {st.session_state.capturing_status}")
        count_placeholder.write(f"**Tiáº¿n trÃ¬nh:** {st.session_state.current_image_count}/{st.session_state.num_samples}")
        
        # Create directories
        output_dir = "data/faces"
        os.makedirs(output_dir, exist_ok=True)
        person_dir = os.path.join(output_dir, st.session_state.folder_name)
        os.makedirs(person_dir, exist_ok=True)
        
        # Start capture process
        if st.session_state.current_image_count < st.session_state.num_samples:
            detector = load_face_detector()
            
            # Open camera only once
            cap = cv2.VideoCapture(0)
            if not cap.isOpened():
                st.error("KhÃ´ng thá»ƒ má»Ÿ camera!")
                st.session_state.capture_running = False
            else:
                # Camera capture loop
                frame_count = 0
                delay_frames = 3
                last_capture_time = time.time()
                min_capture_interval = 0.1  # Minimum 0.1 second between captures
                
                while st.session_state.capture_running and st.session_state.current_image_count < st.session_state.num_samples:
                    ret, frame = cap.read()
                    if not ret:
                        st.error("KhÃ´ng thá»ƒ Ä‘á»c tá»« camera!")
                        break
                    
                    # Flip frame for mirror effect
                    frame = cv2.flip(frame, 1)
                    
                    # Detect faces
                    faces, aligned_faces = detector.detect(frame)
                    
                    # Draw on frame
                    display_frame = frame.copy()
                    for face in faces:
                        x, y, w, h = map(int, face[:4])
                        confidence = face[4]
                        
                        # Draw face rectangle
                        cv2.rectangle(display_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                        cv2.putText(display_frame, f"Face: {confidence:.2f}", (x, y-10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
                    
                    # Add status text
                    status_color = (0, 255, 0) if st.session_state.capturing_status == "Capturing" else (0, 0, 255)
                    status_text = st.session_state.capturing_status
                    cv2.putText(display_frame, status_text, (10, 30),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)
                    
                    # Add count text
                    cv2.putText(display_frame, f"Captured: {st.session_state.current_image_count}/{st.session_state.num_samples}", 
                               (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    
                    # Display frame
                    video_placeholder.image(cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB), use_container_width=True)
                    
                    # Update progress displays without rerunning
                    current_time = time.time()
                    progress_placeholder.progress(st.session_state.current_image_count / st.session_state.num_samples)
                    status_placeholder.write(f"**Tráº¡ng thÃ¡i:** {st.session_state.capturing_status}")
                    count_placeholder.write(f"**Tiáº¿n trÃ¬nh:** {st.session_state.current_image_count}/{st.session_state.num_samples}")
                    
                    # Save face if capturing and conditions met
                    if (st.session_state.capturing_status == "Capturing" and 
                        len(aligned_faces) > 0 and 
                        current_time - last_capture_time >= min_capture_interval):
                        
                        # Save the first face detected
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
                        filename = os.path.join(person_dir, f"{st.session_state.current_image_count:04d}_{timestamp}.jpg")
                        cv2.imwrite(filename, aligned_faces[0])
                        
                        # Update count and time
                        st.session_state.current_image_count += 1
                        last_capture_time = current_time
                        
                        # Update display without rerunning
                        progress_placeholder.progress(st.session_state.current_image_count / st.session_state.num_samples)
                        count_placeholder.write(f"**Tiáº¿n trÃ¬nh:** {st.session_state.current_image_count}/{st.session_state.num_samples}")
                    
                    # Minimal delay to allow UI updates
                    time.sleep(0.01)
                    
                    # Break if user stopped or completed
                    if not st.session_state.capture_running or st.session_state.current_image_count >= st.session_state.num_samples:
                        break
                
                cap.release()
    
    # Completion check
    if st.session_state.current_image_count >= st.session_state.num_samples:
        st.success(f"ğŸ‰ HoÃ n thÃ nh! ÄÃ£ chá»¥p {st.session_state.current_image_count} áº£nh")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("Cáº­p nháº­t Database", key="auto_update_db_button"):
                with st.spinner("Äang xÃ¢y dá»±ng database..."):
                    detector = load_face_detector()
                    recognizer = load_face_recognizer()
                    from utils.face_utils import build_face_database
                    total_count = build_face_database(detector, recognizer, output_dir, "data/db_embeddings.pkl")
                    st.success(f"âœ… Database Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t vá»›i {total_count} khuÃ´n máº·t!")
                    st.info("Vui lÃ²ng restart á»©ng dá»¥ng Ä‘á»ƒ Ã¡p dá»¥ng thay Ä‘á»•i.")
        
        with col2:
            if st.button("ÄÄƒng kÃ½ ngÆ°á»i khÃ¡c", key="auto_register_another_button"):
                st.session_state.capture_running = False
                st.session_state.current_image_count = 0
                st.session_state.person_name = ""
                st.session_state.capturing_status = "Ready"
                st.session_state.force_update = True
                st.rerun()

def show_manual_capture_ui():
    """Manual capture interface with real-time face detection"""
    st.markdown("### ğŸ‘† Cháº¿ Ä‘á»™ chá»¥p thá»§ cÃ´ng")
    
    # Initialize session state
    if 'manual_capture_running' not in st.session_state:
        st.session_state.manual_capture_running = False
    if 'manual_current_image_count' not in st.session_state:
        st.session_state.manual_current_image_count = 0
    if 'manual_folder_name' not in st.session_state:
        st.session_state.manual_folder_name = ""
    if 'manual_captured_image' not in st.session_state:
        st.session_state.manual_captured_image = None
    
    # Input form
    col1, col2 = st.columns([3, 1])
    with col1:
        person_name = st.text_input("Há» vÃ  tÃªn", key="manual_person_name")
    with col2:
        num_samples = st.number_input("Sá»‘ áº£nh máº«u", min_value=50, max_value=200, value=100, key="manual_num_samples")
    
    # Control buttons
    col1, col2 = st.columns(2)
    
    with col1:
        start_button = st.button("ğŸš€ Báº¯t Ä‘áº§u", disabled=st.session_state.manual_capture_running, key="manual_start_button")
    with col2:
        stop_button = st.button("â¹ï¸ Dá»«ng", disabled=not st.session_state.manual_capture_running, key="manual_stop_button")
    
    # Instructions
    if st.session_state.manual_capture_running:
        st.info("**Nháº¥n SPACE hoáº·c 'Take Photo' Ä‘á»ƒ chá»¥p áº£nh | Nháº¥n 'Clear Photo' Ä‘á»ƒ xÃ³a vÃ  chá»¥p áº£nh má»›i**")
    
    # Start capture
    if start_button and person_name:
        st.session_state.manual_capture_running = True
        st.session_state.manual_current_image_count = 0
        st.session_state.manual_folder_name = name_to_folder_name(person_name)
        st.session_state.manual_captured_image = None
        st.rerun()
    elif start_button and not person_name:
        st.error("Vui lÃ²ng nháº­p há» tÃªn!")
    
    # Stop capture
    if stop_button:
        st.session_state.manual_