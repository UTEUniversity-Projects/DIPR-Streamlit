import streamlit as st
import cv2
import numpy as np
import open3d as o3d
import os
import plotly.graph_objects as go
from typing import List, Dict, Tuple, Optional

# Import KITTIDetector t·ª´ utils
from utils.kitti_detection import KITTIDetector, prepare_kitti_sample

def plot_3d_visualization(vis_objects: List):
    """T·∫°o hi·ªÉn th·ªã 3D t∆∞∆°ng t√°c b·∫±ng Plotly"""
    fig = go.Figure()
    
    for obj in vis_objects:
        if isinstance(obj, o3d.geometry.PointCloud):
            # Th√™m point cloud
            points = np.asarray(obj.points)
            colors = np.asarray(obj.colors) if obj.has_colors() else None
            
            # L·∫•y m·∫´u point cloud ƒë·ªÉ hi·ªÉn th·ªã t·ªët h∆°n tr√™n tr√¨nh duy·ªát
            if len(points) > 5000:
                indices = np.random.choice(len(points), 5000, replace=False)
                points = points[indices]
                if colors is not None:
                    colors = colors[indices]
            
            # T·∫°o color array
            if colors is not None:
                # Chuy·ªÉn ƒë·ªïi sang ƒë·ªãnh d·∫°ng rgba cho Plotly
                color_vals = [f'rgb({int(r*255)},{int(g*255)},{int(b*255)})' for r, g, b in colors]
            else:
                # S·ª≠ d·ª•ng m√†u m·∫∑c ƒë·ªãnh
                color_vals = 'rgb(100, 100, 255)'
                
            # Th√™m point cloud v√†o figure
            fig.add_trace(go.Scatter3d(
                x=points[:, 0],
                y=points[:, 1],
                z=points[:, 2],
                mode='markers',
                marker=dict(
                    size=1,
                    color=color_vals,
                    opacity=0.7
                ),
                name='Point Cloud'
            ))
        elif isinstance(obj, o3d.geometry.LineSet):
            # Th√™m c√°c ƒë∆∞·ªùng c·ªßa h·ªôp gi·ªõi h·∫°n
            lines = np.asarray(obj.lines)
            points = np.asarray(obj.points)
            colors = np.asarray(obj.colors)
            
            for i, line in enumerate(lines):
                p1, p2 = points[line[0]], points[line[1]]
                
                # L·∫•y m√†u t·ª´ line set n·∫øu c√≥
                color_rgb = colors[i % len(colors)]
                
                # Chuy·ªÉn ƒë·ªïi RGB float sang ƒë·ªãnh d·∫°ng chu·ªói cho Plotly
                color = f'rgb({int(color_rgb[0]*255)}, {int(color_rgb[1]*255)}, {int(color_rgb[2]*255)})'
                
                # Th√™m ƒë∆∞·ªùng v√†o figure
                fig.add_trace(go.Scatter3d(
                    x=[p1[0], p2[0]],
                    y=[p1[1], p2[1]],
                    z=[p1[2], p2[2]],
                    mode='lines',
                    line=dict(color=color, width=5),
                    showlegend=False
                ))
    
    # C·∫≠p nh·∫≠t layout ƒë·ªÉ hi·ªÉn th·ªã t·ªët h∆°n
    fig.update_layout(
        scene=dict(
            xaxis_title='X',
            yaxis_title='Y',
            zaxis_title='Z',
            aspectmode='data',  # Gi·ªØ t·ª∑ l·ªá th·ª±c t·∫ø
            camera=dict(
                up=dict(x=0, y=0, z=1),
                center=dict(x=0, y=0, z=0),
                eye=dict(x=1.5, y=1.5, z=1.0)
            )
        ),
        margin=dict(l=0, r=0, t=0, b=0),
        legend=dict(
            yanchor="top",
            y=0.99,
            xanchor="left",
            x=0.01
        )
    )
    
    return fig

def show():
    # Th√™m ph·∫ßn gi·ªõi thi·ªáu
    with st.expander("üîç Gi·ªõi thi·ªáu v·ªÅ nh·∫≠n d·∫°ng 3D KITTI", expanded=False):
        st.markdown("""
        ### Gi·ªõi thi·ªáu v·ªÅ nh·∫≠n d·∫°ng ƒë·ªëi t∆∞·ª£ng 3D KITTI
        
        T√≠nh nƒÉng nh·∫≠n d·∫°ng ƒë·ªëi t∆∞·ª£ng 3D KITTI s·ª≠ d·ª•ng c√¥ng ngh·ªá ti√™n ti·∫øn ƒë·ªÉ ph√°t hi·ªán xe c·ªô, ng∆∞·ªùi ƒëi b·ªô v√† c√°c ƒë·ªëi t∆∞·ª£ng kh√°c trong m√¥i tr∆∞·ªùng 3D, d·ª±a tr√™n d·ªØ li·ªáu t·ª´ c·∫£m bi·∫øn LiDAR v√† camera.
        
        #### KITTI Dataset
        
        KITTI l√† m·ªôt trong nh·ªØng b·ªô d·ªØ li·ªáu quan tr·ªçng nh·∫•t trong lƒ©nh v·ª±c xe t·ª± l√°i, ƒë∆∞·ª£c thu th·∫≠p b·ªüi Karlsruhe Institute of Technology v√† Toyota Technological Institute t·∫°i Chicago. B·ªô d·ªØ li·ªáu n√†y bao g·ªìm:
        
        - D·ªØ li·ªáu LiDAR 3D t·ª´ c·∫£m bi·∫øn Velodyne
        - H√¨nh ·∫£nh m√†u t·ª´ camera ƒë·ªô ph√¢n gi·∫£i cao
        - Th√¥ng s·ªë hi·ªáu chu·∫©n (calibration) gi·ªØa c√°c c·∫£m bi·∫øn
        - Nh√£n ƒë·ªëi t∆∞·ª£ng: xe h∆°i, ng∆∞·ªùi ƒëi b·ªô, xe ƒë·∫°p, v.v.
        
        #### Ki·∫øn tr√∫c PointPillars
        
        M√¥ h√¨nh nh·∫≠n d·∫°ng 3D s·ª≠ d·ª•ng trong t√≠nh nƒÉng n√†y d·ª±a tr√™n ki·∫øn tr√∫c PointPillars, m·ªôt ph∆∞∆°ng ph√°p hi·ªáu qu·∫£ ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu point cloud:
        
        1. **Pillar Feature Extractor (PFE)**:
           - Chuy·ªÉn ƒë·ªïi point cloud d·∫°ng th∆∞a th·ªõt th√†nh c√°c "c·ªôt" (pillars)
           - Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ c√°c ƒëi·ªÉm trong m·ªói c·ªôt
           - T·∫°o bi·ªÉu di·ªÖn d·∫°ng l∆∞·ªõi 2D c·ªßa kh√¥ng gian 3D
        
        2. **Region Proposal Network (RPN)**:
           - S·ª≠ d·ª•ng ƒë·∫∑c tr∆∞ng t·ª´ PFE ƒë·ªÉ d·ª± ƒëo√°n v·ªã tr√≠ v√† l·ªõp c·ªßa ƒë·ªëi t∆∞·ª£ng
           - T·∫°o ra c√°c bounding box 3D v·ªõi th√¥ng tin v·ªÅ v·ªã tr√≠, k√≠ch th∆∞·ªõc, h∆∞·ªõng
           - T√≠nh ƒëi·ªÉm tin c·∫≠y cho m·ªói d·ª± ƒëo√°n
        
        #### ·ª®ng d·ª•ng trong th·ª±c t·∫ø
        
        Nh·∫≠n d·∫°ng ƒë·ªëi t∆∞·ª£ng 3D c√≥ nhi·ªÅu ·ª©ng d·ª•ng quan tr·ªçng:
        
        - **Xe t·ª± l√°i**: Ph√°t hi·ªán v√† ph√¢n lo·∫°i ƒë·ªëi t∆∞·ª£ng xung quanh xe
        - **Robotics**: Gi√∫p robot c·∫£m nh·∫≠n v√† hi·ªÉu m√¥i tr∆∞·ªùng 3D
        - **ƒê·ªãnh v·ªã v√† l·∫≠p b·∫£n ƒë·ªì (SLAM)**: X√¢y d·ª±ng b·∫£n ƒë·ªì 3D chi ti·∫øt
        - **Th·ª±c t·∫ø tƒÉng c∆∞·ªùng (AR)**: T√≠ch h·ª£p ƒë·ªëi t∆∞·ª£ng ·∫£o v√†o m√¥i tr∆∞·ªùng th·ª±c
        """)
            
    # Th√™m ph·∫ßn h∆∞·ªõng d·∫´n
    with st.expander("üìã H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng", expanded=False):
        st.markdown("""
        ### H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng
        
        #### C√°ch s·ª≠ d·ª•ng t√≠nh nƒÉng nh·∫≠n d·∫°ng 3D KITTI:
        
        1. **Ch·ªçn d·ªØ li·ªáu m·∫´u**
           - Nh·∫≠p s·ªë th·ª© t·ª± m·∫´u t·ª´ t·∫≠p test c·ªßa KITTI dataset (0-7480)
           - Nh·∫•n "T·∫£i ·∫£nh m·∫´u" ƒë·ªÉ t·∫£i d·ªØ li·ªáu t·ª´ m·∫´u ƒë√£ ch·ªçn
        
        2. **Xem d·ªØ li·ªáu**
           - **·∫¢nh g·ªëc**: Hi·ªÉn th·ªã h√¨nh ·∫£nh t·ª´ camera
           - **Point Cloud (2D view)**: Hi·ªÉn th·ªã point cloud ƒë∆∞·ª£c chi·∫øu l√™n ·∫£nh 2D
           - M√†u s·∫Øc c·ªßa ƒëi·ªÉm ph·∫£n √°nh ƒë·ªô s√¢u (kho·∫£ng c√°ch)
        
        3. **Nh·∫≠n d·∫°ng ƒë·ªëi t∆∞·ª£ng**
           - Nh·∫•n "Nh·∫≠n d·∫°ng ƒë·ªëi t∆∞·ª£ng 3D" ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√°t hi·ªán
           - X·ª≠ l√Ω c√≥ th·ªÉ m·∫•t v√†i gi√¢y t√πy thu·ªôc v√†o ƒë·ªô ph·ª©c t·∫°p c·ªßa scene
        
        4. **Xem k·∫øt qu·∫£**
           - **K·∫øt qu·∫£ 2D**: Hi·ªÉn th·ªã bounding box tr√™n ·∫£nh
           - **K·∫øt qu·∫£ 3D**: Hi·ªÉn th·ªã bounding box 3D tr√™n point cloud
           - **Th√¥ng tin ƒë·ªëi t∆∞·ª£ng**: Chi ti·∫øt v·ªÅ c√°c ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c ph√°t hi·ªán
        
        #### Hi·ªÉu k·∫øt qu·∫£ 3D
        
        K·∫øt qu·∫£ 3D hi·ªÉn th·ªã d∆∞·ªõi d·∫°ng bi·ªÉu ƒë·ªì t∆∞∆°ng t√°c m√† b·∫°n c√≥ th·ªÉ:
        - **Xoay**: K√©o ƒë·ªÉ xoay c·∫£nh 3D
        - **Thu ph√≥ng**: Cu·ªôn ƒë·ªÉ ph√≥ng to/nh·ªè
        - **Di chuy·ªÉn**: Nh·∫•n Shift + k√©o ƒë·ªÉ di chuy·ªÉn
        
        M·ªói lo·∫°i ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c hi·ªÉn th·ªã v·ªõi m·ªôt m√†u kh√°c nhau:
        - **Xe h∆°i (Car)**: M√†u ƒë·ªè
        - **Ng∆∞·ªùi ƒëi b·ªô (Pedestrian)**: M√†u xanh l√°
        - **Xe ƒë·∫°p (Cyclist)**: M√†u xanh d∆∞∆°ng
        
        #### C√°ch ƒë·ªçc th√¥ng tin ƒë·ªëi t∆∞·ª£ng
        
        M·ªói ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c hi·ªÉn th·ªã v·ªõi c√°c th√¥ng tin sau:
        - **Lo·∫°i**: Car, Pedestrian, Cyclist
        - **ƒêi·ªÉm tin c·∫≠y**: M·ª©c ƒë·ªô tin c·∫≠y t·ª´ 0-1 (c√†ng cao c√†ng ch√≠nh x√°c)
        - **V·ªã tr√≠**: T·ªça ƒë·ªô (x, y, z) trong kh√¥ng gian 3D
        - **K√≠ch th∆∞·ªõc**: Chi·ªÅu d√†i, r·ªông, cao c·ªßa ƒë·ªëi t∆∞·ª£ng
        - **G√≥c quay**: H∆∞·ªõng c·ªßa ƒë·ªëi t∆∞·ª£ng theo ƒë·ªô
        """)
        
    st.markdown("### Nh·∫≠n d·∫°ng ƒë·ªëi t∆∞·ª£ng 3D KITTI Dataset")
    
    # Ki·ªÉm tra file m√¥ h√¨nh ONNX c√≥ t·ªìn t·∫°i kh√¥ng
    pfe_path = "models/pfe.onnx"
    rpn_path = "models/rpn.onnx"
    
    # Hi·ªÉn th·ªã th√¥ng b√°o n·∫øu kh√¥ng t√¨m th·∫•y model
    if not os.path.exists(pfe_path) or not os.path.exists(rpn_path):
        st.error("Kh√¥ng t√¨m th·∫•y file model ONNX")
        st.warning("""
        C·∫ßn hai file model:
        1. models/pfe.onnx - Pillar Feature Extractor
        2. models/rpn.onnx - Region Proposal Network
        
        B·∫°n c√≥ th·ªÉ t·∫°o c√°c file n√†y b·∫±ng c√°ch ch·∫°y train_pointpillars.py ho·∫∑c t·∫£i v·ªÅ t·ª´ ngu·ªìn c√≥ s·∫µn.
        """)
        return
    
    # Ki·ªÉm tra dataset KITTI c√≥ t·ªìn t·∫°i kh√¥ng
    data_dir = "data/kitti"
    if not os.path.exists(data_dir):
        st.error("Dataset KITTI ch∆∞a ƒë∆∞·ª£c t·∫£i v·ªÅ ho·∫∑c sai ƒë∆∞·ªùng d·∫´n")
        st.info("""
        **ƒê·ªÉ s·ª≠ d·ª•ng ch·ª©c nƒÉng n√†y, b·∫°n c·∫ßn:**
        1. T·∫£i dataset KITTI b·∫±ng c√°ch ch·∫°y:
           ```
           python scripts/download_kitti.py --data_dir data/kitti
           ```
        2. ƒê·∫£m b·∫£o b·∫°n c√≥ hai file pfe.onnx v√† rpn.onnx trong th∆∞ m·ª•c models/
        3. Kh·ªüi ƒë·ªông l·∫°i ·ª©ng d·ª•ng
        """)
        return
    
    try:
        # T·∫£i detector
        with st.spinner("ƒêang t·∫£i m√¥ h√¨nh PointPillars..."):
            detector = KITTIDetector(pfe_path=pfe_path, rpn_path=rpn_path)
            st.success("ƒê√£ t·∫£i model PointPillars th√†nh c√¥ng!")
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i model: {str(e)}")
        st.warning("Kh√¥ng th·ªÉ t·∫£i model PointPillars")
        st.info("Vui l√≤ng ki·ªÉm tra l·∫°i file model v√† th∆∞ vi·ªán onnxruntime")
        return
    
    # Dataset browser
    st.markdown("### Duy·ªát KITTI Test set")
    
    # T·∫°o thanh b√™n ƒë·ªÉ ch·ªçn c√°c t√πy ch·ªçn
    with st.form(key="sample_selection_form"):
        # Usar dos columnas con el mismo ancho
        col1, col2 = st.columns([1, 1])
        
        with col1:
            sample_idx = st.number_input("Ch·ªçn ·∫£nh m·∫´u", min_value=0, max_value=7480, value=0)
        
        with col2:
            # T·∫°o n√∫t t·∫£i ·∫£nh m·∫´u
            st.write("&nbsp;")  # T·∫°o kho·∫£ng tr·ªëng
            load_button = st.form_submit_button("T·∫£i ·∫£nh m·∫´u", type="primary", use_container_width=True)
    
    # X·ª≠ l√Ω khi n√∫t Load ƒë∆∞·ª£c nh·∫•n
    if load_button:
        try:
            with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu m·∫´u..."):
                sample = prepare_kitti_sample(data_dir, sample_idx)
                
                # L∆∞u trong session state
                st.session_state['kitti_sample'] = sample
                st.success(f"ƒê√£ t·∫£i m·∫´u KITTI #{sample_idx}")
                
        except Exception as e:
            st.error(f"L·ªói khi t·∫£i ·∫£nh m·∫´u: {str(e)}")
    
    # Hi·ªÉn th·ªã v√† x·ª≠ l√Ω d·ªØ li·ªáu KITTI
    if 'kitti_sample' in st.session_state:
        sample = st.session_state['kitti_sample']
        
        # Hi·ªÉn th·ªã d·ªØ li·ªáu g·ªëc
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("·∫¢nh g·ªëc")
            st.image(cv2.cvtColor(sample['image'], cv2.COLOR_BGR2RGB), use_container_width=True)
        
        with col2:
            st.subheader("Point Cloud (2D view)")
            # T·∫°o m·ªôt b·∫£n sao c·ªßa ·∫£nh g·ªëc
            pcd_img = sample['image'].copy()
            
            # Hi·ªÉn th·ªã point cloud v·ªõi m√†u d·ª±a tr√™n ƒë·ªô s√¢u
            try:
                # L·∫•y d·ªØ li·ªáu
                point_cloud = sample['point_cloud']
                calibs = sample['calibs']
                
                # Chi·∫øu point cloud l√™n ·∫£nh (d√πng detector method)
                points_3d_cam = detector.project_lidar_to_camera(point_cloud[:, :3], calibs)
                
                # L·ªçc ƒëi·ªÉm n·∫±m tr∆∞·ªõc camera (z > 0)
                mask = points_3d_cam[:, 2] > 0
                points_3d_cam = points_3d_cam[mask]
                point_intensity = point_cloud[mask][:, 3] if point_cloud.shape[1] >= 4 else None
                
                # Chi·∫øu sang ·∫£nh 2D
                if 'P2' in calibs:
                    points_2d = detector.project_to_image(points_3d_cam, calibs, pcd_img.shape)
                    
                    # L·∫•y m·∫´u c√°c ƒëi·ªÉm ƒë·ªÉ gi·∫£m m·∫≠t ƒë·ªô hi·ªÉn th·ªã (hi·ªÉn th·ªã kho·∫£ng 15% s·ªë ƒëi·ªÉm)
                    if len(points_2d) > 500:
                        sample_indices = np.random.choice(len(points_2d), size=max(500, len(points_2d) // 7), replace=False)
                        points_2d = points_2d[sample_indices]
                        depths = points_3d_cam[sample_indices][:, 2]
                    else:
                        depths = points_3d_cam[:, 2]
                    
                    # T·∫°o b·∫£n ƒë·ªì m√†u d·ª±a tr√™n ƒë·ªô s√¢u
                    min_depth = np.min(depths)
                    max_depth = np.max(depths)
                    depth_range = max_depth - min_depth
                    
                    # Ch·ªâ v·∫Ω n·∫øu c√≥ d·ªØ li·ªáu h·ª£p l·ªá
                    if depth_range > 0:
                        # T·∫°o b·∫£n sao v·ªõi ƒë·ªô trong su·ªët ƒë·ªÉ hi·ªÉn th·ªã ƒëi·ªÉm
                        overlay = pcd_img.copy()
                        
                        # V·∫Ω ƒëi·ªÉm v·ªõi m√†u v√† k√≠ch th∆∞·ªõc d·ª±a tr√™n ƒë·ªô s√¢u
                        for i, pt in enumerate(points_2d):
                            x, y = int(pt[0]), int(pt[1])
                            
                            # T√≠nh m√†u d·ª±a tr√™n ƒë·ªô s√¢u (g·∫ßn: ƒë·ªè -> xa: xanh)
                            depth_norm = (depths[i] - min_depth) / depth_range
                            
                            # T·∫°o m√†u t·ª´ colormap jet (ƒë·ªè -> v√†ng -> xanh l√° -> xanh d∆∞∆°ng)
                            r = int(max(0, 255 * (1 - depth_norm * 2)) if depth_norm < 0.5 else 0)
                            g = int(max(0, 255 * (depth_norm * 2)) if depth_norm < 0.5 else max(0, 255 * (2 - depth_norm * 2)))
                            b = int(0 if depth_norm < 0.5 else max(0, 255 * (depth_norm * 2 - 1)))
                            
                            # T√≠nh k√≠ch th∆∞·ªõc ƒëi·ªÉm d·ª±a tr√™n ƒë·ªô s√¢u (ƒëi·ªÉm g·∫ßn l·ªõn h∆°n)
                            point_size = max(1, int(3 * (1 - 0.7 * depth_norm)))
                            
                            # V·∫Ω ƒëi·ªÉm
                            cv2.circle(overlay, (x, y), point_size, (b, g, r), -1)
                        
                        # K·∫øt h·ª£p ·∫£nh g·ªëc v√† overlay v·ªõi ƒë·ªô trong su·ªët
                        alpha = 0.7  # ƒê·ªô ƒë·∫≠m c·ªßa point cloud
                        pcd_img = cv2.addWeighted(overlay, alpha, pcd_img, 1 - alpha, 0)
                        
                        # Th√™m thanh m√†u ƒë·ªÉ tham chi·∫øu
                        h, w = pcd_img.shape[:2]
                        color_bar_width = w // 4
                        color_bar_height = 20
                        color_bar_x = w - color_bar_width - 10
                        color_bar_y = h - color_bar_height - 10
                        
                        # V·∫Ω thanh m√†u
                        for i in range(color_bar_width):
                            ratio = i / color_bar_width
                            r = int(max(0, 255 * (1 - ratio * 2)) if ratio < 0.5 else 0)
                            g = int(max(0, 255 * (ratio * 2)) if ratio < 0.5 else max(0, 255 * (2 - ratio * 2)))
                            b = int(0 if ratio < 0.5 else max(0, 255 * (ratio * 2 - 1)))
                            cv2.line(pcd_img, 
                                   (color_bar_x + i, color_bar_y), 
                                   (color_bar_x + i, color_bar_y + color_bar_height), 
                                   (b, g, r), 1)
                        
                        # Th√™m nh√£n
                        cv2.putText(pcd_img, f"{min_depth:.1f}m", 
                                   (color_bar_x, color_bar_y + color_bar_height + 15), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                        cv2.putText(pcd_img, f"{max_depth:.1f}m", 
                                   (color_bar_x + color_bar_width - 40, color_bar_y + color_bar_height + 15), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                        cv2.putText(pcd_img, "Depth", 
                                   (color_bar_x + color_bar_width // 2 - 20, color_bar_y - 5), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                # Hi·ªÉn th·ªã ·∫£nh v·ªõi point cloud
                st.image(cv2.cvtColor(pcd_img, cv2.COLOR_BGR2RGB), use_container_width=True)
                
            except Exception as e:
                st.warning(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã point cloud tr√™n ·∫£nh: {str(e)}")
                # Hi·ªÉn th·ªã point cloud d·∫°ng raw thay th·∫ø
                st.info("Hi·ªÉn th·ªã point cloud raw view (3D)")
                
                # T·∫°o point cloud open3d
                pcd = o3d.geometry.PointCloud()
                pcd.points = o3d.utility.Vector3dVector(sample['point_cloud'][:, :3])
                
                # Th√™m m√†u d·ª±a tr√™n chi·ªÅu cao
                colors = np.zeros((len(sample['point_cloud']), 3))
                colors[:, 0] = 0.8  # Default color (light blue)
                
                # Color by height
                min_z = np.min(sample['point_cloud'][:, 2])
                max_z = np.max(sample['point_cloud'][:, 2])
                if max_z > min_z:
                    height_colors = (sample['point_cloud'][:, 2] - min_z) / (max_z - min_z)
                    colors[:, 2] = height_colors  # Blue channel varies with height
                
                pcd.colors = o3d.utility.Vector3dVector(colors)
                
                # Hi·ªÉn th·ªã b·∫±ng Plotly
                fig = plot_3d_visualization([pcd])
                st.plotly_chart(fig, use_container_width=True)
        
        # Hi·ªÉn th·ªã n√∫t ph√°t hi·ªán
        detect_button = st.button("Nh·∫≠n d·∫°ng ƒë·ªëi t∆∞·ª£ng 3D", type="primary")
        
        # X·ª≠ l√Ω khi n√∫t Detect ƒë∆∞·ª£c nh·∫•n
        if detect_button:
            with st.spinner("ƒêang ph√¢n t√≠ch..."):
                try:
                    # Ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng
                    detections, scores = detector.detect(sample['point_cloud'])
                    
                    if not detections:
                        st.warning("Kh√¥ng ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng n√†o trong m·∫´u n√†y")
                        return
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£ 2D
                    st.subheader("K·∫øt qu·∫£ 2D")
                    result_2d = detector.visualize_2d(sample['image'].copy(), detections, scores, sample['calibs'])
                    st.image(cv2.cvtColor(result_2d, cv2.COLOR_BGR2RGB), use_container_width=True)
                    
                    # Hi·ªÉn th·ªã 3D
                    st.subheader("K·∫øt qu·∫£ 3D")
                    vis_objects = detector.visualize_3d(sample['point_cloud'], detections, scores)
                    
                    # S·ª≠ d·ª•ng Plotly cho hi·ªÉn th·ªã 3D t∆∞∆°ng t√°c
                    fig = plot_3d_visualization(vis_objects)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # T√≥m t·∫Øt ph√°t hi·ªán
                    st.subheader("Th√¥ng tin ƒë·ªëi t∆∞·ª£ng")
                    
                    # Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt
                    with st.expander("Chi ti·∫øt ƒë·ªëi t∆∞·ª£ng ƒë√£ ph√°t hi·ªán", expanded=True):
                        if len(detections) > 0:
                            # T·∫°o nhi·ªÅu c·ªôt ƒë·ªÉ hi·ªÉn th·ªã th√¥ng tin
                            num_cols = min(3, len(detections))
                            cols = st.columns(num_cols)
                            
                            for i, (detection, score) in enumerate(zip(detections, scores)):
                                with cols[i % num_cols]:
                                    st.markdown(f"**ƒê·ªëi t∆∞·ª£ng {i+1}: {detection['class']}**")
                                    st.markdown(f"- **ƒêi·ªÉm tin c·∫≠y:** {score:.2f}")
                                    st.markdown(f"- **V·ªã tr√≠:** x={detection['location'][0]:.1f}, y={detection['location'][1]:.1f}, z={detection['location'][2]:.1f}")
                                    st.markdown(f"- **K√≠ch th∆∞·ªõc:** {detection['dimensions'][0]:.1f} x {detection['dimensions'][1]:.1f} x {detection['dimensions'][2]:.1f}")
                                    
                                    # Hi·ªÉn th·ªã g√≥c quay (ƒë·ªïi t·ª´ radian sang ƒë·ªô)
                                    rotation_deg = np.degrees(detection['rotation_y'])
                                    st.markdown(f"- **G√≥c quay:** {rotation_deg:.1f}¬∞")
                        else:
                            st.info("Kh√¥ng c√≥ ƒë·ªëi t∆∞·ª£ng n√†o ƒë∆∞·ª£c ph√°t hi·ªán")
                except Exception as e:
                    st.error(f"L·ªói khi ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng: {str(e)}")